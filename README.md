ğŸ§  Jonas

Local-first AI assistant with a neural policy brain.

Jonas is not just a chatbot wrapper around an LLM.

He separates:

ğŸ—£ Language Model â†’ speaks

ğŸ§  Neural Policy Brain â†’ decides how he speaks

ğŸ—‚ Semantic Memory (SQLite + embeddings) â†’ remembers context

ğŸ“Š Online Feedback Loop â†’ learns from your ratings

Fully local.
No cloud APIs.
Runs clean on Apple Silicon.

ğŸ”¥ Philosophy

Most AI assistants are just prompt wrappers.

Jonas is different.

Instead of letting the LLM decide everything, Jonas uses a small PyTorch neural network to:

Adjust temperature dynamically

Control verbosity

Inject subtle humor

Decide how much memory to recall

Learn from /rate feedback

The LLM generates language.

The policy brain shapes behavior.

ğŸ— Architecture
User Input
    â†“
Embedding (local via Ollama)
    â†“
Neural Policy Brain (PyTorch MLP)
    â†“
Memory Recall (SQLite + cosine similarity)
    â†“
LLM (Ollama)
    â†“
Response
    â†“
Optional /rate feedback â†’ trains policy
ğŸ­ Personality

Jonas carries:

Tactical calm operator energy

Intelligent older-brother warmth

Quiet strategic executive clarity

Subtle, controlled wit

Grounded.
Culturally fluent.
Never theatrical.
Never dismissive.

âš™ï¸ Setup (Mac / Apple Silicon Recommended)
1ï¸âƒ£ Install Ollama
brew install ollama
ollama serve
2ï¸âƒ£ Pull models

Recommended:

ollama pull llama3.1:8b
ollama pull nomic-embed-text

(You can use llama3.2:1b for lightweight testing.)

3ï¸âƒ£ Python Setup
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
4ï¸âƒ£ Run Jonas
python -m src.main
ğŸ’¬ Commands
Command	Description
/quit	Exit
/reset	Clear memory
/history	Show recent turns
/rate 0.8	Train Jonas on last response
ğŸ§  Neural Policy Brain

The policy network:

Small PyTorch MLP

Learns from scalar reward (0â€“1)

Saves weights to data/policy.pt

Adapts tone and structure over time

No reinforcement learning frameworks.
No heavy infrastructure.
Just incremental behavioral shaping.

ğŸ”’ Privacy

All inference is local via Ollama.

Memory stored in local SQLite database.

No external API calls.

No telemetry.

ğŸ“ Project Structure
jonas/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ policy_brain.py
â”‚   â”œâ”€â”€ persona.py
â”‚   â”œâ”€â”€ encoder.py
â”‚   â”œâ”€â”€ memory.py
â”‚   â”œâ”€â”€ ollama_client.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chat.db
â”‚   â”œâ”€â”€ policy.pt
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸš€ Roadmap

Planned improvements:

 Policy smoothing (reduce tone switching)

 Working-memory summarization

 Structured task mode

 Optional lightweight GUI

 Long-term preference tagging

 Better reward shaping

ğŸ§© Why Jonas Exists

To experiment with:

Policy steering for LLMs

Local-first AI systems

Minimal RL-style feedback loops

Human-in-the-loop tone adaptation

Jonas is a research playground disguised as a personal assistant.

âš ï¸ Notes

Smaller models (1B) may exaggerate tone.

8B models handle nuance significantly better.

Delete data/policy.pt if you change embedding size.

ğŸª¶ License

MIT